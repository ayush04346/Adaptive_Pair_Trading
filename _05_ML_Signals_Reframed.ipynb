{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3968a2c",
   "metadata": {},
   "source": [
    "# Notebook 05 — ML-Based Signal Diagnostics (Reframed)\n",
    "\n",
    "**Adaptive Pair Trading using Cointegration and Volatility Modeling**  \n",
    "**Author:** Ayush Arora (MQMS2404)\n",
    "\n",
    "---\n",
    "\n",
    "## Objective\n",
    "\n",
    "This notebook uses machine learning models as **probabilistic diagnostic tools** to examine whether\n",
    "short-horizon mean-reversion events in a stationary spread exhibit learnable predictive structure.\n",
    "\n",
    "Given the rarity and stochastic nature of mean-reversion events, model outputs are interpreted as\n",
    "risk-aware signals rather than deterministic classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3106465",
   "metadata": {},
   "source": [
    "## Cell 1: Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a60491c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c17fc2",
   "metadata": {},
   "source": [
    "## Cell 2: Load spread, Z-score, and volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "822988e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Date\n",
       " 2015-01-01   -7.063013\n",
       " 2015-01-02   -6.987348\n",
       " 2015-01-05   -5.824623\n",
       " 2015-01-06   -6.484915\n",
       " 2015-01-07   -6.006633\n",
       " Name: 0, dtype: float64,\n",
       " Date\n",
       " 2015-01-01   -0.312319\n",
       " 2015-01-02   -0.302455\n",
       " 2015-01-05   -0.150890\n",
       " 2015-01-06   -0.236962\n",
       " 2015-01-07   -0.174616\n",
       " Name: 0, dtype: float64,\n",
       " Date\n",
       " 2015-01-02    0.643896\n",
       " 2015-01-05    0.631061\n",
       " 2015-01-06    0.669407\n",
       " 2015-01-07    0.671586\n",
       " 2015-01-08    0.666134\n",
       " Name: garch_vol, dtype: float64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spread = pd.read_csv('data\\spread_tatasteel_hindalco.csv', index_col=0, parse_dates=True).iloc[:,0]\n",
    "zscore = pd.read_csv('data\\zscore_tatasteel_hindalco.csv', index_col=0, parse_dates=True).iloc[:,0]\n",
    "garch_vol = pd.read_csv('data\\garch_vol_tatsteel_hindalco.csv', index_col=0, parse_dates=True).iloc[:,0]\n",
    "\n",
    "spread.head(), zscore.head(), garch_vol.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7abae6",
   "metadata": {},
   "source": [
    "## Cell 3: Feature construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41c871f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spread</th>\n",
       "      <th>zscore</th>\n",
       "      <th>spread_lag1</th>\n",
       "      <th>spread_lag2</th>\n",
       "      <th>volatility</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-05</th>\n",
       "      <td>-5.824623</td>\n",
       "      <td>-0.150890</td>\n",
       "      <td>-6.987348</td>\n",
       "      <td>-7.063013</td>\n",
       "      <td>0.631061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-06</th>\n",
       "      <td>-6.484915</td>\n",
       "      <td>-0.236962</td>\n",
       "      <td>-5.824623</td>\n",
       "      <td>-6.987348</td>\n",
       "      <td>0.669407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-07</th>\n",
       "      <td>-6.006633</td>\n",
       "      <td>-0.174616</td>\n",
       "      <td>-6.484915</td>\n",
       "      <td>-5.824623</td>\n",
       "      <td>0.671586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-08</th>\n",
       "      <td>-6.402756</td>\n",
       "      <td>-0.226252</td>\n",
       "      <td>-6.006633</td>\n",
       "      <td>-6.484915</td>\n",
       "      <td>0.666134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-09</th>\n",
       "      <td>-6.622972</td>\n",
       "      <td>-0.254958</td>\n",
       "      <td>-6.402756</td>\n",
       "      <td>-6.006633</td>\n",
       "      <td>0.658258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              spread    zscore  spread_lag1  spread_lag2  volatility\n",
       "Date                                                                \n",
       "2015-01-05 -5.824623 -0.150890    -6.987348    -7.063013    0.631061\n",
       "2015-01-06 -6.484915 -0.236962    -5.824623    -6.987348    0.669407\n",
       "2015-01-07 -6.006633 -0.174616    -6.484915    -5.824623    0.671586\n",
       "2015-01-08 -6.402756 -0.226252    -6.006633    -6.484915    0.666134\n",
       "2015-01-09 -6.622972 -0.254958    -6.402756    -6.006633    0.658258"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'spread': spread,\n",
    "    'zscore': zscore,\n",
    "    'spread_lag1': spread.shift(1),\n",
    "    'spread_lag2': spread.shift(2),\n",
    "    'volatility': garch_vol\n",
    "})\n",
    "\n",
    "df = df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472ee51d",
   "metadata": {},
   "source": [
    "## Cell 4: Mean-reversion label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7afe0b8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "revert\n",
       "0    0.715213\n",
       "1    0.284787\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "horizon = 5\n",
    "future_spread = df['spread'].shift(-horizon)\n",
    "\n",
    "df['revert'] = (\n",
    "    (df['spread'] * future_spread < 0) |\n",
    "    (np.abs(future_spread) < 0.8 * np.abs(df['spread']))\n",
    ").astype(int)\n",
    "\n",
    "df = df.dropna()\n",
    "df['revert'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04e3710",
   "metadata": {},
   "source": [
    "## Cell 5: Train-test split (no shuffling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edeac4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns='revert')\n",
    "y = df['revert']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95b33ec",
   "metadata": {},
   "source": [
    "## Cell 6: Logistic Regression (probability diagnostics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e09d9e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold=0.00: Precision=0.388, Recall=1.000, F1=0.559\n",
      "Threshold=0.10: Precision=0.388, Recall=1.000, F1=0.559\n",
      "Threshold=0.20: Precision=0.405, Recall=0.951, F1=0.568\n",
      "Threshold=0.30: Precision=0.481, Recall=0.519, F1=0.499\n",
      "Threshold=0.40: Precision=0.451, Recall=0.111, F1=0.179\n",
      "Threshold=0.50: Precision=0.300, Recall=0.042, F1=0.073\n",
      "Threshold=0.60: Precision=0.000, Recall=0.000, F1=0.000\n",
      "Threshold=0.70: Precision=0.000, Recall=0.000, F1=0.000\n",
      "Threshold=0.80: Precision=0.000, Recall=0.000, F1=0.000\n",
      "Threshold=0.90: Precision=0.000, Recall=0.000, F1=0.000\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "logit = LogisticRegression(max_iter=1000)\n",
    "logit.fit(X_train_scaled, y_train)\n",
    "\n",
    "probs_logit = logit.predict_proba(X_test_scaled)[:,1]\n",
    "\n",
    "for thr in np.arange(0, 1, 0.1):\n",
    "    preds = (probs_logit > thr).astype(int)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        y_test, preds, average='binary', zero_division=0\n",
    "    )\n",
    "    print(f\"Threshold={thr:.2f}: Precision={precision:.3f}, Recall={recall:.3f}, F1={f1:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102bd127",
   "metadata": {},
   "source": [
    "## Cell 7: Random Forest (nonlinear diagnostics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "633b55dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold=0.00: Precision=0.388, Recall=1.000, F1=0.559\n",
      "Threshold=0.10: Precision=0.388, Recall=1.000, F1=0.559\n",
      "Threshold=0.20: Precision=0.405, Recall=0.951, F1=0.568\n",
      "Threshold=0.30: Precision=0.481, Recall=0.519, F1=0.499\n",
      "Threshold=0.40: Precision=0.451, Recall=0.111, F1=0.179\n",
      "Threshold=0.50: Precision=0.300, Recall=0.042, F1=0.073\n",
      "Threshold=0.60: Precision=0.000, Recall=0.000, F1=0.000\n",
      "Threshold=0.70: Precision=0.000, Recall=0.000, F1=0.000\n",
      "Threshold=0.80: Precision=0.000, Recall=0.000, F1=0.000\n",
      "Threshold=0.90: Precision=0.000, Recall=0.000, F1=0.000\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=300, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "probs_rf = rf.predict_proba(X_test)[:,1]\n",
    "\n",
    "for thr in np.arange(0, 1, 0.1):\n",
    "    preds = (probs_logit > thr).astype(int)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        y_test, preds, average='binary', zero_division=0\n",
    "    )\n",
    "    print(f\"Threshold={thr:.2f}: Precision={precision:.3f}, Recall={recall:.3f}, F1={f1:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a346b4c1",
   "metadata": {},
   "source": [
    "## Cell 8: Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48f8ea94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "volatility     0.269523\n",
       "spread_lag2    0.192028\n",
       "spread_lag1    0.183882\n",
       "zscore         0.179788\n",
       "spread         0.174779\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(rf.feature_importances_, index=X.columns).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96097639",
   "metadata": {},
   "source": [
    "## Final Conclusion\n",
    "\n",
    "ML models exhibit conservative behavior across probability thresholds,\n",
    "indicating weak predictability of fixed-horizon mean reversion.\n",
    "\n",
    "This supports the interpretation of ML as a risk-filtering mechanism\n",
    "rather than a deterministic signal generator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d6242d",
   "metadata": {},
   "source": [
    "### Interpretation of Probability Threshold Sweep\n",
    "\n",
    "The threshold sweep reveals a clear precision–recall trade-off.\n",
    "Lower thresholds capture most mean-reversion events but generate\n",
    "substantial false positives, while higher thresholds suppress trading\n",
    "activity entirely.\n",
    "\n",
    "This behavior reflects the diffuse and regime-dependent nature of\n",
    "mean reversion in financial spreads. Machine learning models therefore\n",
    "serve as conservative risk filters rather than deterministic predictors.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
